{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is where we use the Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raslindn\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a guide on what you need, https://anaconda.org/anaconda/gensim <---- Gensim\n",
    "#       What does the error message mean?\n",
    "\n",
    "import pandas as pd              # pandas is a dataframe library\n",
    "import matplotlib.pyplot as plt  # matplotlib.pyplot plots data\n",
    "import numpy as np               # numpy provides N-dim object support\n",
    "\n",
    "# do ploting inline instead of in a separate window\n",
    "%matplotlib inline\n",
    "\n",
    "### Algorithms ###\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.cross_validation import train_test_split # Used to split data into Training set and Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the post data\n",
    "#df = pd.read_csv(\"../EncodedCSVFiles/DataFame10kEncoded.csv\")\n",
    "#df= pd.read_csv(\"../EncodedCSVFiles/DataFame100kEncoded.csv\")\n",
    "df = pd.read_csv(\"../EncodedCSVFiles/DataFame1MEncoded.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing with a Custom Hot One Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/37292872/how-can-i-one-hot-encode-in-python <--- This is dank stuff\n",
    "\n",
    "#TODO:\n",
    "# Concider changing this to Word Embedding instead (Gensim)\n",
    "# Concider to add new information instead of re-reading everything\n",
    "# Should be saved into three different file?\n",
    "\n",
    "#from sklearn.feature_extraction import DictVectorizer\n",
    "#dictVector = DictVectorizer(sparse = False, sort = False)\n",
    "#qualitative_features = ['Name', 'Street', 'City']\n",
    "#X_qual = dictVector.fit_transform(df[qualitative_features].to_dict('records'))\n",
    "# Print the List\n",
    "#dictVector.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "#df.ix[[0, 33, 39, 55]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Debug #\n",
    "#df.loc[df['Name'] == 7]\n",
    "#df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>SurName</th>\n",
       "      <th>Street</th>\n",
       "      <th>StreetNr</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>City</th>\n",
       "      <th>Legitimate</th>\n",
       "      <th>StartStreet</th>\n",
       "      <th>StartStreetNr</th>\n",
       "      <th>StartZipCode</th>\n",
       "      <th>StartCity</th>\n",
       "      <th>EndStreet</th>\n",
       "      <th>EndStreetNr</th>\n",
       "      <th>EndZipCode</th>\n",
       "      <th>EndCity</th>\n",
       "      <th>CorrectDelivery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28</td>\n",
       "      <td>73</td>\n",
       "      <td>30178</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>11222</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>30222</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "      <td>35174</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>11222</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>35222</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>41</td>\n",
       "      <td>137</td>\n",
       "      <td>41136</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>11222</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>41222</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>28</td>\n",
       "      <td>87</td>\n",
       "      <td>97178</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>11222</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>97222</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>85175</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>11222</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>85222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name  SurName  Street  StreetNr  ZipCode  City  Legitimate  StartStreet  \\\n",
       "0  27.0     27.0      28        73    30178  -1.0           1           24   \n",
       "1  38.0     39.0      23        40    35174  18.0           1           24   \n",
       "2  26.0     26.0      41       137    41136  13.0           1           24   \n",
       "3  43.0     45.0      28        87    97178  19.0           1           24   \n",
       "4  69.0     68.0      17        30    85175   2.0           1           24   \n",
       "\n",
       "   StartStreetNr  StartZipCode  StartCity  EndStreet  EndStreetNr  EndZipCode  \\\n",
       "0              1         11222          7         24            1       30222   \n",
       "1              1         11222          7         24            1       35222   \n",
       "2              1         11222          7         24            1       41222   \n",
       "3              1         11222          7          4            1       97222   \n",
       "4              1         11222          7         24            1       85222   \n",
       "\n",
       "   EndCity  CorrectDelivery  \n",
       "0     -1.0                1  \n",
       "1     18.0                1  \n",
       "2     13.0                1  \n",
       "3     19.0                0  \n",
       "4      2.0                1  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for null values\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(816552, 16)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows the RowsxColumns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check True/False Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of True cases: 701928 (85.96%)\n",
      "Number of False cases: 114624 (14.04%)\n"
     ]
    }
   ],
   "source": [
    "num_true = len(df.loc[df['CorrectDelivery'] == True])\n",
    "num_false = len(df.loc[df['CorrectDelivery'] == False])\n",
    "\n",
    "print(\"Number of True cases: {0} ({1:2.2f}%)\".format(num_true, (num_true / (num_true + num_false)) * 100))\n",
    "print(\"Number of False cases: {0} ({1:2.2f}%)\".format(num_false, (num_false / (num_true + num_false)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Divides the Train data and Test data into a 70/30 split\n",
    "\n",
    "#X_train = pd.get_dummies(df)\n",
    "#X_test = pd.get_dummies(df)\n",
    "\n",
    "\n",
    "feature_col_names = ['Name', 'City', 'Street', 'StreetNr', 'ZipCode', 'SurName', 'StartStreet', 'StartZipCode', 'StartCity', 'EndStreet', 'EndZipCode', 'EndCity', 'StartStreetNr', 'EndStreetNr']\n",
    "prediction_class_name = ['CorrectDelivery']\n",
    "\n",
    "#ddf = pd.get_dummies(df)\n",
    "\n",
    "X = df[feature_col_names].values     # predictor feature columnd (8 X m)\n",
    "y = df[prediction_class_name].values # predicted calss (1 = true, 0 = false) column (1 X m)\n",
    "split_test_size = 0.7\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = split_test_size, random_state = 42) # 42 is the answer to everything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.00% in training set\n",
      "70.00% in test set\n"
     ]
    }
   ],
   "source": [
    "#Print to check if the split was to our liking\n",
    "\n",
    "print(\"{0:0.2f}% in training set\".format((len(X_train)/len(df.index)) * 100))\n",
    "print(\"{0:0.2f}% in test set\".format((len(X_test)/len(df.index)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying predicted value was split correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original True  : 701928 (85.96%)\n",
      "Original False : 114624 (14.04%)\n",
      "\n",
      "Training True  : 210489 (85.93%)\n",
      "Training False : 34476 (14.07%)\n",
      "\n",
      "Test True      : 491439 (85.98%)\n",
      "Test False     : 80148 (14.02%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original True  : {0} ({1:0.2f}%)\".format(len(df.loc[df['CorrectDelivery'] == 1]), len(df.loc[df['CorrectDelivery'] == 1]) / len(df.index) * 100))\n",
    "print(\"Original False : {0} ({1:0.2f}%)\".format(len(df.loc[df['CorrectDelivery'] == 0]), len(df.loc[df['CorrectDelivery'] == 0]) / len(df.index) * 100))\n",
    "print(\"\")\n",
    "print(\"Training True  : {0} ({1:0.2f}%)\".format(len(y_train[y_train[:] == 1]), len(y_train[y_train[:] == 1]) / len(y_train) * 100))\n",
    "print(\"Training False : {0} ({1:0.2f}%)\".format(len(y_train[y_train[:] == 0]), len(y_train[y_train[:] == 0]) / len(y_train) * 100))\n",
    "print(\"\")\n",
    "print(\"Test True      : {0} ({1:0.2f}%)\".format(len(y_test[y_test[:] == 1]), len(y_test[y_test[:] == 1]) / len(y_test) * 100))\n",
    "print(\"Test False     : {0} ({1:0.2f}%)\".format(len(y_test[y_test[:] == 0]), len(y_test[y_test[:] == 0]) / len(y_test) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement tries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now since we have rougly 70-30 split in our data regarding true and false outcomes, we know the class is unbalanced and it should be because people do not misswrite 50% of the adresses. Ergo we do not need to ponder about this.\n",
    "\n",
    "Moving on, the first thing to try is to increase the recall score which is a metric for the models performance since it is calcultated based upon how good the model was at predicting the outcome.\n",
    "http://stackoverflow.com/questions/31421413/how-to-compute-precision-recall-accuracy-and-f1-score-for-the-multiclass-case\n",
    "http://stackoverflow.com/questions/30746460/how-to-interpret-scikits-learn-confusion-matrix-and-classification-report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets start with trying to find the best parameters for regular logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firt lets try to get the highest recall score based on the regularization varible C, which is the inverse of the regularization strentgh, ergo the lower value the stronger regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd              # pandas is a dataframe library\n",
    "import matplotlib.pyplot as plt  # matplotlib.pyplot plots data\n",
    "import numpy as np               # numpy provides N-dim object support\n",
    "\n",
    "# do ploting inline instead of in a separate window\n",
    "%matplotlib inline\n",
    "\n",
    "### Algorithms ###\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "### Cross Validation ###\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "### Splitting the data ###\n",
    "from sklearn.model_selection import train_test_split \n",
    "### Evaluation metrics ###\n",
    "from sklearn import metrics\n",
    "#[[True-Positive, False-Negative]\n",
    "#[False-Positive, True-Negative]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[481502   9937]\n",
      " [ 54510  25638]]\n",
      "Accuracy: 0.8872490\n",
      "Recall: 0.9797798\n",
      "Precision: 0.8983045\n"
     ]
    }
   ],
   "source": [
    "#model = RandomForestClassifier(random_state=42, n_jobs=-1, n_estimators=16, max_features=1.0, min_samples_leaf=2)\n",
    "#1.193015e-6 for B and 9,899918e-7 for A\n",
    "model = LogisticRegression(random_state=42, n_jobs=-1, C= 1.193015e-6)\n",
    "model.fit(X_train, y_train.ravel())\n",
    "predict = model.predict(X_test)\n",
    "print(\"{0}\".format(metrics.confusion_matrix(y_test.ravel(), predict, labels = [1, 0])))\n",
    "print (\"Accuracy: {0:.7f}\".format(metrics.accuracy_score(y_test.ravel(), predict)))\n",
    "print (\"Recall: {0:.7f}\".format(metrics.recall_score(y_test.ravel(), predict)))\n",
    "print (\"Precision: {0:.7f}\".format(metrics.precision_score(y_test.ravel(), predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision\n",
      "[ 359381.36638046]\n",
      "Accuracy: 0.8871230\n",
      "Recall: 0.9791938\n",
      "Precision: 0.8986122\n",
      "ACCURACY\n",
      "[  1.07226722e-07]\n",
      "Accuracy: 0.8879996\n",
      "Recall: 0.9836297\n",
      "Precision: 0.8962246\n",
      "RECALL\n",
      "[  1.00000000e-10]\n",
      "Accuracy: 0.8597799\n",
      "Recall: 1.0000000\n",
      "Precision: 0.8597799\n"
     ]
    }
   ],
   "source": [
    "cslist = np.logspace(-10, 10, 100)\n",
    "print(\"Precision\")\n",
    "model = LogisticRegressionCV(n_jobs = -1, cv = 10, refit = True, random_state = 42, scoring='precision', Cs = cslist)\n",
    "\n",
    "trained = model.fit(X_train, y_train.ravel())\n",
    "\n",
    "predict = trained.predict(X_test)\n",
    "\n",
    "print (trained.C_)\n",
    "\n",
    "print (\"Accuracy: {0:.7f}\".format(metrics.accuracy_score(y_test.ravel(), predict)))\n",
    "print (\"Recall: {0:.7f}\".format(metrics.recall_score(y_test.ravel(), predict)))\n",
    "print (\"Precision: {0:.7f}\".format(metrics.precision_score(y_test.ravel(), predict)))\n",
    "\n",
    "print(\"ACCURACY\")\n",
    "model = LogisticRegressionCV(n_jobs = -1, cv = 10, refit = True, random_state = 42, scoring='accuracy', Cs = cslist)\n",
    "\n",
    "trained = model.fit(X_train, y_train.ravel())\n",
    "\n",
    "predict = trained.predict(X_test)\n",
    "\n",
    "print (trained.C_)\n",
    "\n",
    "print (\"Accuracy: {0:.7f}\".format(metrics.accuracy_score(y_test.ravel(), predict)))\n",
    "print (\"Recall: {0:.7f}\".format(metrics.recall_score(y_test.ravel(), predict)))\n",
    "print (\"Precision: {0:.7f}\".format(metrics.precision_score(y_test.ravel(), predict)))\n",
    "\n",
    "print (\"RECALL\")\n",
    "model = LogisticRegressionCV(n_jobs = -1, cv = 10, refit = True, random_state = 42, scoring='recall', Cs = cslist)\n",
    "\n",
    "trained = model.fit(X_train, y_train.ravel())\n",
    "\n",
    "predict = trained.predict(X_test)\n",
    "\n",
    "print (trained.C_)\n",
    "\n",
    "print (\"Accuracy: {0:.7f}\".format(metrics.accuracy_score(y_test.ravel(), predict)))\n",
    "print (\"Recall: {0:.7f}\".format(metrics.recall_score(y_test.ravel(), predict)))\n",
    "print (\"Precision: {0:.7f}\".format(metrics.precision_score(y_test.ravel(), predict)))\n",
    "featurerangelist = [.1,.2,.3,.4,.5,.6,.7,.8,.9,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "'''\n",
    "C_start = 0.0000001\n",
    "C_end = 0.000001\n",
    "C_increment = 0.00000001\n",
    "\n",
    "#start at 0.1 as C then go all the way up to 5 to find the best fit\n",
    "C_values, recall_scores = [], []\n",
    "#save the recall score and the C\n",
    "\n",
    "C_val = C_start\n",
    "#what we are looking for \n",
    "best_recall_score = 0\n",
    "\n",
    "while (C_val < C_end):\n",
    "    C_values.append(C_val)\n",
    "    #train\n",
    "    lr_model_loop = LogisticRegression(C=C_val, random_state=42)\n",
    "    lr_model_loop.fit(X_train, y_train.ravel())\n",
    "    #predict\n",
    "    lr_predict_loop_test = lr_model_loop.predict(X_test)\n",
    "    recall_score = metrics.recall_score(y_test, lr_predict_loop_test)\n",
    "    recall_scores.append(recall_score)\n",
    "    #save the best value\n",
    "    if(recall_score > best_recall_score):\n",
    "        best_recall_score = recall_score\n",
    "        best_lr_predict_test = lr_predict_loop_test\n",
    "    #increment the c val\n",
    "    C_val = C_val + C_increment\n",
    "\n",
    "#plot the regulazation values vs the recall score\n",
    "best_score_C_val = C_values[recall_scores.index(best_recall_score)]\n",
    "print(\"1st max recall {0:.10f} at C={1:.10f}\".format(best_recall_score, best_score_C_val))\n",
    "print(\"Acc {0:.10f}\".format(metrics.accuracy_score(y_test.ravel(), lr_predict_loop_test)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above loop takes 4ever to run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.72357\n",
      "99.69790\n",
      "99.68253\n",
      "99.65846\n",
      "99.64978\n",
      "99.64068\n",
      "99.63037\n",
      "99.61906\n",
      "99.61017\n",
      "99.61361\n",
      "0.997235730116\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kf = KFold(n_splits=10, random_state=42)\n",
    "iteration = 0\n",
    "rangelist = [1,2,3,4,5,6,7,8,9,10]\n",
    "bestvalue = 0\n",
    "bestit = 0\n",
    "tempval = 0\n",
    "\n",
    "while (iteration < len(rangelist)):\n",
    "    \n",
    "    model = RandomForestClassifier(random_state=42, n_jobs=-1, n_estimators=16, max_features=1.0, min_samples_leaf=rangelist[iteration])\n",
    "    \n",
    "    model.fit(X_train, y_train.ravel())\n",
    "    predicted = model.predict(X_test)\n",
    "    tempval = (metrics.precision_score(y_test.ravel(), predicted))\n",
    "    iteration = iteration + 1\n",
    "    print (\"{0:.5f}\".format(tempval*100))\n",
    "    if(tempval > bestvalue):\n",
    "        bestvalue = tempval\n",
    "        bestit = iteration\n",
    "    \n",
    "    \n",
    "    #print(rangelist[iteration])\n",
    "    #print (\"{0:.7f}\".format(metrics.accuracy_score(y_test.ravel(), predicted)))\n",
    "    #print (\"{0:.7f}\".format(metrics.recall_score(y_test.ravel(), predicted)))\n",
    "    \n",
    "\n",
    "    #print(metrics.classification_report(y_test, predictedcv, labels = [1, 0])) \n",
    "           \n",
    "print(bestvalue)\n",
    "print(bestit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
